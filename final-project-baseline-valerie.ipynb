{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test data: assess shape to confirm we have way more observations in the test set than in the training set.   \n",
    "\n",
    "\n",
    "Considerations: normalization, feature selection, multilevel structure, metrics that are relevant (false positives, false negatives, etc.)  \n",
    "A lot less data in the training set than in the test set. It needs to generalize well!   \n",
    "\n",
    "Data cleaning: what do we do about NaN values?\n",
    "\n",
    "\n",
    "Baseline: simple linear model \n",
    "\n",
    "Could use a ton of models, based on papers I have found:\n",
    "- Multinomial regression\n",
    "- Random forest\n",
    "- Neural networks\n",
    "\n",
    "How to leverage ensemble methods to obtain the best result?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('forest-cover-type-prediction/train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15121, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan],\n",
       "       [ 1.000e+00,  2.596e+03,  5.100e+01,  3.000e+00,  2.580e+02,\n",
       "         0.000e+00,  5.100e+02,  2.210e+02,  2.320e+02,  1.480e+02,\n",
       "         6.279e+03,  1.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         5.000e+00],\n",
       "       [ 2.000e+00,  2.590e+03,  5.600e+01,  2.000e+00,  2.120e+02,\n",
       "        -6.000e+00,  3.900e+02,  2.200e+02,  2.350e+02,  1.510e+02,\n",
       "         6.225e+03,  1.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         5.000e+00],\n",
       "       [ 3.000e+00,  2.804e+03,  1.390e+02,  9.000e+00,  2.680e+02,\n",
       "         6.500e+01,  3.180e+03,  2.340e+02,  2.380e+02,  1.350e+02,\n",
       "         6.121e+03,  1.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  1.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         2.000e+00],\n",
       "       [ 4.000e+00,  2.785e+03,  1.550e+02,  1.800e+01,  2.420e+02,\n",
       "         1.180e+02,  3.090e+03,  2.380e+02,  2.380e+02,  1.220e+02,\n",
       "         6.211e+03,  1.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  1.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,\n",
       "         2.000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    1\n",
       "34    1\n",
       "35    1\n",
       "36    1\n",
       "37    1\n",
       "38    1\n",
       "39    1\n",
       "40    1\n",
       "41    1\n",
       "42    1\n",
       "43    1\n",
       "44    1\n",
       "45    1\n",
       "46    1\n",
       "47    1\n",
       "48    1\n",
       "49    1\n",
       "50    1\n",
       "51    1\n",
       "52    1\n",
       "53    1\n",
       "54    1\n",
       "55    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate non-null subset\n",
    "df_sub = df.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0             1             2             3             4   \\\n",
      "count  15120.00000  15120.000000  15120.000000  15120.000000  15120.000000   \n",
      "mean    7560.50000   2749.322553    156.676653     16.501587    227.195701   \n",
      "std     4364.91237    417.678187    110.085801      8.453927    210.075296   \n",
      "min        1.00000   1863.000000      0.000000      0.000000      0.000000   \n",
      "25%     3780.75000   2376.000000     65.000000     10.000000     67.000000   \n",
      "50%     7560.50000   2752.000000    126.000000     15.000000    180.000000   \n",
      "75%    11340.25000   3104.000000    261.000000     22.000000    330.000000   \n",
      "max    15120.00000   3849.000000    360.000000     52.000000   1343.000000   \n",
      "\n",
      "                 5             6             7             8             9   \\\n",
      "count  15120.000000  15120.000000  15120.000000  15120.000000  15120.000000   \n",
      "mean      51.076521   1714.023214    212.704299    218.965608    135.091997   \n",
      "std       61.239406   1325.066358     30.561287     22.801966     45.895189   \n",
      "min     -146.000000      0.000000      0.000000     99.000000      0.000000   \n",
      "25%        5.000000    764.000000    196.000000    207.000000    106.000000   \n",
      "50%       32.000000   1316.000000    220.000000    223.000000    138.000000   \n",
      "75%       79.000000   2270.000000    235.000000    235.000000    167.000000   \n",
      "max      554.000000   6890.000000    254.000000    254.000000    248.000000   \n",
      "\n",
      "       ...            46            47            48            49  \\\n",
      "count  ...  15120.000000  15120.000000  15120.000000  15120.000000   \n",
      "mean   ...      0.045635      0.040741      0.001455      0.006746   \n",
      "std    ...      0.208699      0.197696      0.038118      0.081859   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                 50            51            52            53            54  \\\n",
      "count  15120.000000  15120.000000  15120.000000  15120.000000  15120.000000   \n",
      "mean       0.000661      0.002249      0.048148      0.043452      0.030357   \n",
      "std        0.025710      0.047368      0.214086      0.203880      0.171574   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "                 55  \n",
      "count  15120.000000  \n",
      "mean       4.000000  \n",
      "std        2.000066  \n",
      "min        1.000000  \n",
      "25%        2.000000  \n",
      "50%        4.000000  \n",
      "75%        6.000000  \n",
      "max        7.000000  \n",
      "\n",
      "[8 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_sub.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zip = pd.read_csv(\"forest-cover-type-prediction/train.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15120, 56)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zip.shape\n",
    "#This appears to be the same dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We have loaded our csv training data\n",
    "#We know what the columns mean\n",
    "0. count\n",
    "1. elevation\n",
    "2. aspect\n",
    "3. slope\n",
    "4. Horizontal_Distance_To_Hydrology\n",
    "5. Horizontal_Distance_To_Roadways\n",
    "6. Hillshade_9am\n",
    "7. Hillshade_Noon\n",
    "8. Hillshade_3pm\n",
    "9. Horizontal_Distance_To_Fire_Points  \n",
    "10-13. Wilderness_Area  \n",
    "14-54. Soil_Type  \n",
    "55. Cover_Type (our output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
